{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('D:/Data Science/Symbiosis/Dataset/diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(columns=[\"Outcome\"])\n",
    "y=df[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest= train_test_split(x,y,test_size = 0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model=SVC(kernel=\"linear\",C=1)\n",
    "model.fit(xtrain,ytrain)\n",
    "ypred=model.predict(xtest)\n",
    "\n",
    "#from sklearn.svm import SVC\n",
    "#model=SVC(kernel=\"rbf\",C=1)\n",
    "#model.fit(xtrain,ytrain)\n",
    "#ypred=model.predict(xtest)\n",
    "\n",
    "#model=SVC(kernel=\"polynomial\",C=1)\n",
    "#model.fit(xtrain,ytrain)\n",
    "#ypred=model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model is: 0.8181818181818182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "acc=accuracy_score(ytest,ypred)\n",
    "cm=confusion_matrix(ytest,ypred)\n",
    "print(\"Accuracy of model is:\",acc)\n",
    "sns.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87       107\n",
      "           1       0.74      0.62      0.67        47\n",
      "\n",
      "    accuracy                           0.82       154\n",
      "   macro avg       0.79      0.76      0.77       154\n",
      "weighted avg       0.81      0.82      0.81       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVC in module sklearn.svm._classes:\n",
      "\n",
      "class SVC(sklearn.svm._base.BaseSVC)\n",
      " |  SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |  \n",
      " |  C-Support Vector Classification.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time scales at least\n",
      " |  quadratically with the number of samples and may be impractical\n",
      " |  beyond tens of thousands of samples. For large datasets\n",
      " |  consider using :class:`~sklearn.svm.LinearSVC` or\n",
      " |  :class:`~sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
      " |  :class:`~sklearn.kernel_approximation.Nystroem` transformer.\n",
      " |  \n",
      " |  The multiclass support is handled according to a one-vs-one scheme.\n",
      " |  \n",
      " |  For details on the precise mathematical formulation of the provided\n",
      " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      " |  other, see the corresponding section in the narrative documentation:\n",
      " |  :ref:`svm_kernels`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  C : float, default=1.0\n",
      " |      Regularization parameter. The strength of the regularization is\n",
      " |      inversely proportional to C. Must be strictly positive. The penalty\n",
      " |      is a squared l2 penalty.\n",
      " |  \n",
      " |  kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}, default='rbf'\n",
      " |      Specifies the kernel type to be used in the algorithm.\n",
      " |      It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      " |      a callable.\n",
      " |      If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |      used to pre-compute the kernel matrix from data matrices; that matrix\n",
      " |      should be an array of shape ``(n_samples, n_samples)``.\n",
      " |  \n",
      " |  degree : int, default=3\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : {'scale', 'auto'} or float, default='scale'\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      - if ``gamma='scale'`` (default) is passed then it uses\n",
      " |        1 / (n_features * X.var()) as value of gamma,\n",
      " |      - if 'auto', uses 1 / n_features.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
      " |  \n",
      " |  coef0 : float, default=0.0\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  shrinking : bool, default=True\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |      See the :ref:`User Guide <shrinking_svm>`.\n",
      " |  \n",
      " |  probability : bool, default=False\n",
      " |      Whether to enable probability estimates. This must be enabled prior\n",
      " |      to calling `fit`, will slow down that method as it internally uses\n",
      " |      5-fold cross-validation, and `predict_proba` may be inconsistent with\n",
      " |      `predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
      " |  \n",
      " |  tol : float, default=1e-3\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  cache_size : float, default=200\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default=None\n",
      " |      Set the parameter C of class i to class_weight[i]*C for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, default=-1\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  decision_function_shape : {'ovo', 'ovr'}, default='ovr'\n",
      " |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      " |      (n_samples, n_classes) as all other classifiers, or the original\n",
      " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      " |      (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
      " |      ('ovo') is always used as multi-class strategy. The parameter is\n",
      " |      ignored for binary classification.\n",
      " |  \n",
      " |      .. versionchanged:: 0.19\n",
      " |          decision_function_shape is 'ovr' by default.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *decision_function_shape='ovr'* is recommended.\n",
      " |  \n",
      " |      .. versionchanged:: 0.17\n",
      " |         Deprecated *decision_function_shape='ovo' and None*.\n",
      " |  \n",
      " |  break_ties : bool, default=False\n",
      " |      If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n",
      " |      :term:`predict` will break ties according to the confidence values of\n",
      " |      :term:`decision_function`; otherwise the first class among the tied\n",
      " |      classes is returned. Please note that breaking ties comes at a\n",
      " |      relatively high computational cost compared to a simple predict.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the pseudo random number generation for shuffling the data for\n",
      " |      probability estimates. Ignored when `probability` is False.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  class_weight_ : ndarray of shape (n_classes,)\n",
      " |      Multipliers of parameter C for each class.\n",
      " |      Computed based on the ``class_weight`` parameter.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels.\n",
      " |  \n",
      " |  coef_ : ndarray of shape (n_classes * (n_classes - 1) / 2, n_features)\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  dual_coef_ : ndarray of shape (n_classes -1, n_SV)\n",
      " |      Dual coefficients of the support vector in the decision\n",
      " |      function (see :ref:`sgd_mathematical_formulation`), multiplied by\n",
      " |      their targets.\n",
      " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      " |      The layout of the coefficients in the multiclass case is somewhat\n",
      " |      non-trivial. See the :ref:`multi-class section of the User Guide\n",
      " |      <svm_multi_class>` for details.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (n_classes * (n_classes - 1) / 2,)\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  support_ : ndarray of shape (n_SV)\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : ndarray of shape (n_SV, n_features)\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  n_support_ : ndarray of shape (n_classes,), dtype=int32\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  probA_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
      " |  probB_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
      " |      If `probability=True`, it corresponds to the parameters learned in\n",
      " |      Platt scaling to produce probability estimates from decision values.\n",
      " |      If `probability=False`, it's an empty array. Platt scaling uses the\n",
      " |      logistic function\n",
      " |      ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
      " |      where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
      " |      more information on the multiclass case and training procedure see\n",
      " |      section 8 of [1]_.\n",
      " |  \n",
      " |  shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
      " |      Array dimensions of training vector ``X``.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.pipeline import make_pipeline\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      " |  >>> y = np.array([1, 1, 2, 2])\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
      " |  >>> clf.fit(X, y)\n",
      " |  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      " |                  ('svc', SVC(gamma='auto'))])\n",
      " |  \n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SVR : Support Vector Machine for Regression implemented using libsvm.\n",
      " |  \n",
      " |  LinearSVC : Scalable Linear Support Vector Machine for classification\n",
      " |      implemented using liblinear. Check the See Also section of\n",
      " |      LinearSVC for more comparison element.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] `LIBSVM: A Library for Support Vector Machines\n",
      " |      <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
      " |  \n",
      " |  .. [2] `Platt, John (1999). \"Probabilistic outputs for support vector\n",
      " |      machines and comparison to regularizedlikelihood methods.\"\n",
      " |      <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639>`_\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVC\n",
      " |      sklearn.svm._base.BaseSVC\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.svm._base.BaseLibSVM\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Evaluates the decision function for the samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : ndarray of shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Returns the decision function of the sample for each class\n",
      " |          in the model.\n",
      " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      " |          n_classes).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If decision_function_shape='ovo', the function values are proportional\n",
      " |      to the distance of the samples X to the separating hyperplane. If the\n",
      " |      exact distances are required, divide the function values by the norm of\n",
      " |      the weight vector (``coef_``). See also `this question\n",
      " |      <https://stats.stackexchange.com/questions/14876/\n",
      " |      interpreting-distance-from-hyperplane-in-svm>`_ for further details.\n",
      " |      If decision_function_shape='ovr', the decision function is a monotonic\n",
      " |      transformation of ovo decision function.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 or -1 is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          Class labels for samples in X.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  predict_log_proba\n",
      " |      Compute log probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the log-probabilities of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  predict_proba\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  probA_\n",
      " |  \n",
      " |  probB_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)                 or (n_samples, n_samples)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |  \n",
      " |  n_support_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tunning of svn hyper parameter\n",
    "#model\n",
    "model=SVC()\n",
    "\n",
    "#parameter\n",
    "kernel=[\"linear\",\"poly\",\"rbf\",\"sigmoid\"]\n",
    "C=[100,50,10,1,0.1,0.01]\n",
    "gamma=[\"scale\",\"auto\"]\n",
    "\n",
    "#grid\n",
    "grid={\"kernel\":kernel,\"C\":C,\"gamma\":gamma}\n",
    "\n",
    "#cv\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "cv=RepeatedStratifiedKFold(n_splits=5,n_repeats=3,random_state=1)\n",
    "\n",
    "#grid Search cv\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_cv=GridSearchCV(estimator=model,param_grid=grid,cv=cv,scoring=\"accuracy\")\n",
    "\n",
    "#result\n",
    "res=grid_cv.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
